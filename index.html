<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Digit Recognizer Demo</title>
    <!-- Load p5.js and TensorFlow.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.1/p5.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: #f4f7f9;
            color: #333;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            margin: 0;
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 20px;
        }
        .container {
            display: flex;
            gap: 25px;
            justify-content: center;
            align-items: flex-start;
            flex-wrap: wrap;
            width: 100%;
            max-width: 1200px; /* Limit overall width */
        }
        .card {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            align-items: center;
            min-width: 300px; /* Ensure cards don't get too small */
        }
        .card h2 {
            margin-top: 0;
            margin-bottom: 15px;
            color: #34495e;
            font-size: 1.2em;
            text-align: center;
        }
        /* Canvas styling */
        #input-canvas-container canvas,
        #nn-visualization-container canvas {
            border: 2px solid #e1e8ed;
            border-radius: 4px;
            margin-top: 10px; /* Spacing */
        }
        #input-canvas-container canvas {
             cursor: crosshair;
        }

        button#clear-button {
            margin-top: 15px;
            padding: 10px 20px;
            font-size: 1em;
            cursor: pointer;
            background-color: #e74c3c;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.2s ease;
        }
        button#clear-button:hover {
            background-color: #c0392b;
        }
        button#clear-button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }

        #prediction-output {
            font-size: 3.5em;
            font-weight: bold;
            color: #2980b9;
            margin: 10px 0;
            min-height: 60px; /* Prevent layout shift */
            line-height: 1;
        }
         #status {
            font-style: italic;
            color: #7f8c8d;
            height: 20px; /* Reserve space */
            margin-bottom: 15px;
            text-align: center;
        }

        #confidence-bars {
            width: 100%;
            max-width: 250px; /* Limit width of bars section */
            margin-top: 10px;
        }
        .confidence-entry {
            display: flex;
            align-items: center;
            margin-bottom: 4px;
            font-size: 0.9em;
        }
        .confidence-label {
             width: 65px; /* Label width (e.g., "Digit 5:") */
             flex-shrink: 0;
             color: #555;
        }
        .confidence-bar-bg {
            flex-grow: 1;
            height: 15px;
            background-color: #ecf0f1;
            border-radius: 3px;
            overflow: hidden; /* Clip the inner bar */
            margin-left: 5px;
        }
        .confidence-bar {
            height: 100%;
            background-color: #3498db;
            width: 0%; /* Start at 0% */
            border-radius: 3px;
            transition: width 0.3s ease-out;
            text-align: right;
            color: white;
            font-size: 0.8em;
            line-height: 15px; /* Center text vertically */
            padding-right: 3px;
            box-sizing: border-box; /* Include padding in width */
            white-space: nowrap; /* Prevent text wrapping */
            overflow: hidden; /* Hide text if bar is too small */
        }
        .confidence-bar.highlight {
             background-color: #2ecc71; /* Highlight predicted digit */
        }
    </style>
</head>
<body>
    <h1>Interactive Digit Recognizer</h1>
    <div id="status">Loading Libraries...</div>

    <div class="container">
        <!-- Input Card -->
        <div class="card" id="input-canvas-container">
            <h2>Draw a Digit (0-9)</h2>
            <!-- p5.js will create canvas here -->
            <button id="clear-button" disabled>Clear</button>
        </div>

        <!-- Visualization Card -->
        <div class="card" id="nn-visualization-container">
            <h2>Network Prediction (Simplified)</h2>
            <!-- p5.js will create visualization canvas here -->
        </div>

        <!-- Output Card -->
        <div class="card" id="output-container">
            <h2>Prediction</h2>
            <div id="prediction-output">?</div>
            <div id="confidence-bars">
                 <!-- Confidence bars will be added here -->
            </div>
        </div>
    </div>

    <script>
        let inputCanvas;
        let nnCanvas; // This will be a p5 Graphics object
        let model;
        let prediction = "?";
        let confidences = [];
        let nnVizData = { layers: [], activations: [], predictedDigit: null };
        let isDrawing = false;
        let graphicsBuffer; // Off-screen buffer for drawing (28x28)

        const INPUT_SIZE = 28;
        const DRAW_SCALE = 10; // Draw on a larger canvas (280x280)
        const CANVAS_WIDTH = INPUT_SIZE * DRAW_SCALE;
        const CANVAS_HEIGHT = INPUT_SIZE * DRAW_SCALE;

        const NN_VIS_WIDTH = 300;
        const NN_VIS_HEIGHT = 250;

        // --- p5.js Sketch ---

        function setup() {
             select('#status').html('Initializing Canvas...');
            // --- Input Canvas ---
            let inputContainer = select('#input-canvas-container');
            inputCanvas = createCanvas(CANVAS_WIDTH, CANVAS_HEIGHT);
            inputCanvas.parent(inputContainer); // Attach to the container div
            inputCanvas.style('display', 'block'); // Prevent extra space below canvas

            // Create a smaller off-screen buffer for the actual 28x28 input
            graphicsBuffer = createGraphics(INPUT_SIZE, INPUT_SIZE);
            graphicsBuffer.pixelDensity(1); // Ensure correct pixel density

            // --- Visualization Canvas ---
            // We use createGraphics so we can draw to it independently
            // and then attach its canvas element to the DOM.
            let nnContainer = select('#nn-visualization-container');
            nnCanvas = createGraphics(NN_VIS_WIDTH, NN_VIS_HEIGHT);
            nnCanvas.parent(nnContainer); // Attach its underlying canvas element
            nnCanvas.style('display', 'block');

            // --- Initialize State & UI ---
            clearDrawing(); // Set initial background and clear buffer
            initializeNetworkVisualization(); // Set up basic viz structure
            drawNeuralNetworkVisualization(); // Initial draw of the NN structure
            updateConfidenceBars([]); // Initial empty bars

            // --- Button Listener ---
            select('#clear-button').mousePressed(clearDrawing);

            // --- Load Model ---
            loadTFModel(); // Start loading the model asynchronously
        }

        function draw() {
            // --- Handle Drawing Input on the main canvas ---
            if (mouseIsPressed && isMouseOverInputCanvas()) {
                isDrawing = true;
                // Draw thick black line on main input canvas (scaled)
                stroke(0); // Black ink
                strokeWeight(DRAW_SCALE * 1.5); // Adjust thickness relative to scale
                line(pmouseX, pmouseY, mouseX, mouseY);

                // Draw thinner white line on the small internal graphics buffer (scaled down)
                graphicsBuffer.stroke(255); // White ink on black background
                graphicsBuffer.strokeWeight(2); // Suitable thickness for 28x28
                graphicsBuffer.line(
                    pmouseX / DRAW_SCALE, pmouseY / DRAW_SCALE,
                    mouseX / DRAW_SCALE, mouseY / DRAW_SCALE
                );
            }
        }

        function mouseReleased() {
            // Only predict if drawing occurred over the input canvas
            if (isDrawing && isMouseOverInputCanvas(true)) {
                 isDrawing = false; // Reset drawing flag AFTER check
                if (model) { // Only predict if model is loaded
                   predictDigit();
                } else {
                    console.warn("Model not loaded yet.");
                    select('#status').html('Model not loaded yet.');
                }
            } else {
                // If mouse released elsewhere or wasn't drawing, ensure flag is false
                isDrawing = false;
            }
        }

        // Helper to check if mouse is over the *input* canvas
        // pass checkRelease=true if called from mouseReleased to be less strict about boundaries
        function isMouseOverInputCanvas(checkRelease = false) {
            // Get position relative to the page, not just the p5 canvas
            const canvasRect = inputCanvas.elt.getBoundingClientRect();
            const mouseCheckX = checkRelease ? mouseX : pmouseX; // Use previous mouse pos unless releasing
            const mouseCheckY = checkRelease ? mouseY : pmouseY;

             // Check if the relevant mouse position is within the input canvas bounds
            return (
                mouseCheckX >= canvasRect.left && mouseCheckX <= canvasRect.right &&
                mouseCheckY >= canvasRect.top && mouseCheckY <= canvasRect.bottom
            );

        }

        function clearDrawing() {
            background(255); // Clear main input canvas (white background)
            graphicsBuffer.background(0); // Clear buffer (black background for MNIST)
            prediction = "?";
            confidences = [];
            select('#prediction-output').html(prediction);
            updateConfidenceBars(confidences);
            resetNetworkVisualization();
            drawNeuralNetworkVisualization(); // Redraw static structure
            isDrawing = false; // Reset drawing state
             if (model) select('#status').html('Model Loaded. Ready to draw!');
        }

        // --- TensorFlow.js Model Handling ---

        async function loadTFModel() {
            const statusDiv = select('#status');
            statusDiv.html('Loading Model... Please Wait.'); // Update status
            try {
                console.log("Loading model...");
                 // --- THIS IS THE CORRECTED/UPDATED URL ---
                model = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-examples/mnist-layers/model.json');
                // --- END OF CORRECTION ---

                console.log("Model loaded successfully.");
                statusDiv.html('Model Loaded. Ready to draw!');
                select('#clear-button').removeAttribute('disabled'); // Enable button
                 initializeNetworkVisualization(model); // Re-init with actual model info if needed
                 drawNeuralNetworkVisualization(); // Redraw NN

            } catch (error) {
                console.error("Error loading model:", error);
                statusDiv.html('Error loading model. Check console.');
            }
        }

        async function predictDigit() {
            if (!model) {
                console.log("Model not available.");
                 select('#status').html('Model not loaded!');
                return;
            }

            const statusDiv = select('#status');
            statusDiv.html('Predicting...');
            select('#prediction-output').html('...'); // Indicate processing

            // Use a short delay to allow UI to update before potential blocking TF code
            await new Promise(resolve => setTimeout(resolve, 10));

            try {
                await tf.tidy(() => { // Use tf.tidy to automatically manage tensor memory

                    // 1. Get image data from the small graphics buffer
                    // Need the underlying canvas element for fromPixels
                    const graphicsCanvas = graphicsBuffer.elt;

                    // 2. Convert to TensorFlow tensor
                    let tensor = tf.browser.fromPixels(graphicsCanvas, 1) // 1 channel (grayscale)
                        // .resizeBilinear([INPUT_SIZE, INPUT_SIZE]) // Resize might not be needed if buffer is exact, but good practice
                        .toFloat() // Convert to float
                        .div(tf.scalar(255)) // Normalize 0-255 -> 0-1
                        .expandDims(0); // Add batch dimension: [1, 28, 28, 1]

                    // console.log("Input Tensor Shape:", tensor.shape); // Should be [1, 28, 28, 1]

                    // 3. Make prediction
                    let outputTensor = model.predict(tensor);

                    // 4. Process output tensor
                    // Use await data() for async version, preferred over dataSync
                    // confidences = await outputTensor.data(); // returns TypedArray
                    confidences = Array.from(outputTensor.dataSync()); // Use sync and convert for simplicity here

                    let maxConfidence = 0;
                    let predictedDigit = 0;

                    confidences.forEach((confidence, digit) => {
                        if (confidence > maxConfidence) {
                            maxConfidence = confidence;
                            predictedDigit = digit;
                        }
                    });

                    prediction = `${predictedDigit}`;

                    // 5. Update UI
                    select('#prediction-output').html(prediction);
                    updateConfidenceBars(confidences, predictedDigit);
                    updateNetworkVisualization(confidences, predictedDigit); // Update NN viz based on prediction
                    drawNeuralNetworkVisualization(); // Redraw the NN with highlights

                }); // End of tf.tidy block

                 statusDiv.html('Prediction Complete.');

            } catch(error) {
                 console.error("Error during prediction:", error);
                 statusDiv.html('Error during prediction.');
                 select('#prediction-output').html('Error');
            }
        }


        // --- Visualization Functions ---

        function initializeNetworkVisualization(loadedModel = null) {
            // Basic static representation based on the known model structure or default
             let layersInfo = [
                { count: 784, label: 'Input (28x28)', type: 'input' }, // Represent input pixels
                { count: 16, label: 'Conv2D', type: 'hidden' },       // Typical layers in TF.js MNIST examples
                { count: 32, label: 'Conv2D', type: 'hidden' },
                { count: 64, label: 'Dense', type: 'hidden' },
                { count: 10, label: 'Output', type: 'output' }        // Output layer (digits 0-9)
             ];
             // Could try to inspect model layers:
             // if (loadedModel && loadedModel.layers) { ... parse layers ... }

            nnVizData = {
                layers: layersInfo,
                activations: Array(layersInfo[layersInfo.length - 1].count).fill(0), // Activations for output layer
                predictedDigit: null
            };
        }

        function resetNetworkVisualization() {
             if (nnVizData.activations) nnVizData.activations.fill(0);
             nnVizData.predictedDigit = null;
        }

        function updateNetworkVisualization(outputConfidences, predictedDigit) {
            // Update activations for the output layer based on prediction
            nnVizData.activations = outputConfidences; // Assuming outputConfidences is a plain array now
            nnVizData.predictedDigit = predictedDigit;
        }

        // Draws the NN structure and highlights onto the nnCanvas graphics object
        function drawNeuralNetworkVisualization() {
            const nn = nnCanvas; // Target the p5 Graphics object
            nn.push(); // Isolate drawing styles

            nn.background(248, 250, 252); // Light background for the viz canvas
            nn.textAlign(nn.CENTER, nn.CENTER);
            nn.textSize(10);

            const layerSpacing = nn.width / (nnVizData.layers.length + 1);
            const maxNodesToShow = 10; // Limit nodes per layer for clarity

            for (let i = 0; i < nnVizData.layers.length; i++) {
                const layer = nnVizData.layers[i];
                const x = layerSpacing * (i + 1);

                // Draw Layer Label
                nn.fill(100);
                nn.noStroke();
                nn.text(layer.label, x, 15);

                const nodeCount = Math.min(layer.count, maxNodesToShow);
                const nodeSpacing = (nn.height - 60) / Math.max(1, nodeCount); // Vertical spacing (use nodeCount directly)
                const startY = 40 + nodeSpacing / 2; // Start position adjusted for spacing

                // Draw connections (simplified lines between layer centers)
                if (i > 0) {
                    const prevX = layerSpacing * i;
                    nn.stroke(200, 200, 200, 100); // Light grey connections
                    nn.strokeWeight(1);
                    // Draw a few representative lines
                    const numConnections = Math.min(nodeCount, 5); // Draw fewer connections for clarity
                     for (let j = 0; j < numConnections; j++) {
                         const y = startY + j * nodeSpacing * (nodeCount/numConnections); // Spread out connections
                         const prevNodeCount = Math.min(nnVizData.layers[i-1].count, maxNodesToShow);
                         const prevNodeSpacing = (nn.height - 60) / Math.max(1, prevNodeCount);
                         const prevStartY = 40 + prevNodeSpacing / 2;
                         const prevY = prevStartY + (j % prevNodeCount) * prevNodeSpacing; // Connect to different previous nodes
                         nn.line(prevX, prevY, x, y);
                     }
                }

                // Draw Nodes
                for (let j = 0; j < nodeCount; j++) {
                    const y = startY + j * nodeSpacing;
                    let nodeSize = (layer.type === 'output' || layer.type === 'input') ? 10 : 7;
                    let nodeColor = nn.color(200); // Default grey
                    let nodeStroke = nn.color(180);
                    let nodeStrokeWeight = 1;

                    if (layer.type === 'output') {
                        const activation = (nnVizData.activations && nnVizData.activations[j]) ? nnVizData.activations[j] : 0;
                        // Color based on activation strength (blue intensity)
                        nodeColor = nn.lerpColor(nn.color(230), nn.color(52, 152, 219, 255), activation);
                        nodeSize = 8 + activation * 8; // Size based on activation

                        if (j === nnVizData.predictedDigit) {
                            nodeColor = nn.color(46, 204, 113); // Highlight predicted green
                            nodeStroke = nn.color(39, 174, 96);
                            nodeStrokeWeight = 2;
                            nodeSize = 18; // Make predicted larger
                        }

                         // Draw digit label next to output node
                         nn.fill(50);
                         nn.noStroke();
                         nn.textSize(9);
                         nn.textAlign(nn.LEFT, nn.CENTER);
                         nn.text(j, x + nodeSize / 2 + 5, y);
                         nn.textAlign(nn.CENTER, nn.CENTER); // Reset alignment
                    } else if (layer.type === 'input') {
                         nodeColor = nn.color(210);
                         nodeSize = 3; // Input nodes smaller
                    }

                    nn.fill(nodeColor);
                    nn.stroke(nodeStroke);
                    nn.strokeWeight(nodeStrokeWeight);
                    nn.ellipse(x, y, nodeSize, nodeSize);
                }
                 if (layer.count > maxNodesToShow) {
                     nn.fill(150);
                     nn.noStroke();
                     nn.text("...", x, nn.height - 15);
                 }
            }
            nn.pop(); // Restore drawing styles
        }


        function updateConfidenceBars(confidences, predictedDigit = -1) {
            let barsContainer = select('#confidence-bars');
            barsContainer.html(''); // Clear previous bars

            if (!confidences || confidences.length === 0) {
                 barsContainer.html('<p style="font-size: 0.9em; color: #888;">Draw a digit to see confidences.</p>');
                return;
            }

            for (let i = 0; i < confidences.length; i++) {
                let confidence = confidences[i] || 0; // Ensure confidence is not undefined/null
                let percentage = (confidence * 100);

                // Create entry container
                let entry = createDiv('');
                entry.parent(barsContainer);
                entry.addClass('confidence-entry');

                // Create Label
                let label = createSpan(`Digit ${i}:`);
                label.parent(entry);
                label.addClass('confidence-label');

                // Create Bar Background
                let barBg = createDiv('');
                barBg.parent(entry);
                barBg.addClass('confidence-bar-bg');

                // Create Inner Bar
                let bar = createDiv(percentage.toFixed(1) + '%');
                bar.parent(barBg);
                bar.addClass('confidence-bar');
                // Use setTimeout to apply width after element is added to DOM for transition
                setTimeout(() => { bar.style('width', `${Math.max(0, Math.min(100, percentage))}%`); }, 10);


                if (i === predictedDigit) {
                    bar.addClass('highlight'); // Add highlight class if it's the prediction
                }
            }
        }

    </script>

</body>
</html>
